{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#This notebook is to scrape data from fbref website specifically for Big 5 european Football League player performance metrics."
      ],
      "metadata": {
        "id": "29vQoQ99sl_U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Manually change the season for which you would like to scrape Big 5 European Football league performance data for (from 2017-18 to 2023-24)"
      ],
      "metadata": {
        "id": "JTEqnKIQtwma"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8KIfa1MKnzZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "season = \"2017-2018\"\n"
      ],
      "metadata": {
        "id": "hEWGXkABOTHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scraper for fbref standard table\n",
        "url_standard = f\"https://fbref.com/en/comps/Big5/{season}/stats/players/{season}-Big-5-European-Leagues-Stats\"\n",
        "df_standard = pd.read_html(url_standard, attrs={\"id\": \"stats_standard\"})[0]\n",
        "\n",
        "df_standard.columns = [\n",
        "    '_'.join(col).strip() if isinstance(col, tuple) and 'Unnamed' not in col[0] else col[-1]\n",
        "    for col in df_standard.columns\n",
        "]\n",
        "df_standard.columns = df_standard.columns.str.strip().str.replace(r'\\s+', '_', regex=True)\n",
        "if 'Matches' in df_standard.columns:\n",
        "    df_standard = df_standard.drop(columns=['Matches'])\n",
        "df_standard.to_csv(f\"fbref_standard_{season}.csv\", index=False)\n",
        "print(f\"Saved standard stats to fbref_standard_{season}.csv\")\n"
      ],
      "metadata": {
        "id": "8j3z8vZDuTrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scraper for fbref defense table\n",
        "url_defense = f\"https://fbref.com/en/comps/Big5/{season}/defense/players/{season}-Big-5-European-Leagues-Stats\"\n",
        "\n",
        "df_defense = pd.read_html(url_defense, attrs={\"id\": \"stats_defense\"})[0]\n",
        "df_defense.columns = [\n",
        "    '_'.join(col).strip() if isinstance(col, tuple) and 'Unnamed' not in col[0] else col[-1]\n",
        "    for col in df_defense.columns\n",
        "]\n",
        "df_defense.columns = df_defense.columns.str.strip().str.replace(r'\\s+', '_', regex=True)\n",
        "if 'Matches' in df_defense.columns:\n",
        "    df_defense = df_defense.drop(columns=['Matches'])\n",
        "\n",
        "df_defense.to_csv(f\"fbref_defense_{season}.csv\", index=False)\n",
        "print(f\"Saved defense stats to fbref_defense_{season}.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKam8TGCKtmg",
        "outputId": "70c0bc6d-809f-4f33-9e65-a0ff4bff60e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved defense stats to fbref_defense_2017-2018.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scraper for fbref keepers table\n",
        "url_keepers = f\"https://fbref.com/en/comps/Big5/{season}/keepers/players/{season}-Big-5-European-Leagues-Stats\"\n",
        "\n",
        "df_keepers = pd.read_html(url_keepers, attrs={\"id\": \"stats_keeper\"})[0]\n",
        "df_keepers.columns = [\n",
        "    '_'.join(col).strip() if isinstance(col, tuple) and 'Unnamed' not in col[0] else col[-1]\n",
        "    for col in df_keepers.columns\n",
        "]\n",
        "df_keepers.columns = df_keepers.columns.str.strip().str.replace(r'\\s+', '_', regex=True)\n",
        "if 'Matches' in df_keepers.columns:\n",
        "    df_keepers = df_keepers.drop(columns=['Matches'])\n",
        "\n",
        "df_keepers.to_csv(f\"fbref_keepers_{season}.csv\", index=False)\n",
        "print(f\"Saved keeper stats to fbref_keepers_{season}.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AUhVyUdKygB",
        "outputId": "40a9818b-96b2-4c9b-8f92-f4b08d330c16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved keeper stats to fbref_keepers_2017-2018.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scraper for fbref passing table\n",
        "url_passing = f\"https://fbref.com/en/comps/Big5/{season}/passing/players/{season}-Big-5-European-Leagues-Stats\"\n",
        "\n",
        "df_passing = pd.read_html(url_passing, attrs={\"id\": \"stats_passing\"})[0]\n",
        "df_passing.columns = [\n",
        "    '_'.join(col).strip() if isinstance(col, tuple) and 'Unnamed' not in col[0] else col[-1]\n",
        "    for col in df_passing.columns\n",
        "]\n",
        "df_passing.columns = df_passing.columns.str.strip().str.replace(r'\\s+', '_', regex=True)\n",
        "if 'Matches' in df_passing.columns:\n",
        "    df_passing = df_passing.drop(columns=['Matches'])\n",
        "\n",
        "df_passing.to_csv(f\"fbref_passing_{season}.csv\", index=False)\n",
        "print(f\"Saved passing stats to fbref_passing_{season}.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHwSHHG6K0md",
        "outputId": "2a1ca490-294c-45c3-d59e-61daad869f69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved passing stats to fbref_passing_2017-2018.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scraper for fbref possession table\n",
        "url_possession = f\"https://fbref.com/en/comps/Big5/{season}/possession/players/{season}-Big-5-European-Leagues-Stats\"\n",
        "\n",
        "df_possession = pd.read_html(url_possession, attrs={\"id\": \"stats_possession\"})[0]\n",
        "df_possession.columns = [\n",
        "    '_'.join(col).strip() if isinstance(col, tuple) and 'Unnamed' not in col[0] else col[-1]\n",
        "    for col in df_possession.columns\n",
        "]\n",
        "df_possession.columns = df_possession.columns.str.strip().str.replace(r'\\s+', '_', regex=True)\n",
        "if 'Matches' in df_possession.columns:\n",
        "    df_possession = df_possession.drop(columns=['Matches'])\n",
        "\n",
        "df_possession.to_csv(f\"fbref_possession_{season}.csv\", index=False)\n",
        "print(f\"Saved possession stats to fbref_possession_{season}.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0PC3RR5K23i",
        "outputId": "0096fd60-7ac1-4443-c853-8da0d591575b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved possession stats to fbref_possession_2017-2018.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scraper for fbref shooting table\n",
        "url_shooting = f\"https://fbref.com/en/comps/Big5/{season}/shooting/players/{season}-Big-5-European-Leagues-Stats\"\n",
        "\n",
        "df_shooting = pd.read_html(url_shooting, attrs={\"id\": \"stats_shooting\"})[0]\n",
        "df_shooting.columns = [\n",
        "    '_'.join(col).strip() if isinstance(col, tuple) and 'Unnamed' not in col[0] else col[-1]\n",
        "    for col in df_shooting.columns\n",
        "]\n",
        "df_shooting.columns = df_shooting.columns.str.strip().str.replace(r'\\s+', '_', regex=True)\n",
        "if 'Matches' in df_shooting.columns:\n",
        "    df_shooting = df_shooting.drop(columns=['Matches'])\n",
        "\n",
        "df_shooting.to_csv(f\"fbref_shooting_{season}.csv\", index=False)\n",
        "print(f\"Saved shooting stats to fbref_shooting_{season}.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5kB-CBzK5z3",
        "outputId": "3146da1b-7ea3-4354-8511-034afa75cce1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved shooting stats to fbref_shooting_2017-2018.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scraper for fbref miscellaneous table\n",
        "url_misc = f\"https://fbref.com/en/comps/Big5/{season}/misc/players/{season}-Big-5-European-Leagues-Stats\"\n",
        "\n",
        "df_misc = pd.read_html(url_misc, attrs={\"id\": \"stats_misc\"})[0]\n",
        "df_misc.columns = [\n",
        "    '_'.join(col).strip() if isinstance(col, tuple) and 'Unnamed' not in col[0] else col[-1]\n",
        "    for col in df_misc.columns\n",
        "]\n",
        "df_misc.columns = df_misc.columns.str.strip().str.replace(r'\\s+', '_', regex=True)\n",
        "if 'Matches' in df_misc.columns:\n",
        "    df_misc = df_misc.drop(columns=['Matches'])\n",
        "\n",
        "df_misc.to_csv(f\"fbref_misc_{season}.csv\", index=False)\n",
        "print(f\"Saved miscellaneous stats to fbref_misc_{season}.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OT0Jep9iK_Fu",
        "outputId": "b605de34-7493-4365-87e2-fbf5666cc340"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved miscellaneous stats to fbref_misc_2017-2018.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scraper for fbref advanced keepers table\n",
        "url_keepers_adv = f\"https://fbref.com/en/comps/Big5/{season}/keepersadv/players/{season}-Big-5-European-Leagues-Stats\"\n",
        "\n",
        "df_keepers_adv = pd.read_html(url_keepers_adv, attrs={\"id\": \"stats_keeper_adv\"})[0]\n",
        "df_keepers_adv.columns = [\n",
        "    '_'.join(col).strip() if isinstance(col, tuple) and 'Unnamed' not in col[0] else col[-1]\n",
        "    for col in df_keepers_adv.columns\n",
        "]\n",
        "df_keepers_adv.columns = df_keepers_adv.columns.str.strip().str.replace(r'\\s+', '_', regex=True)\n",
        "if 'Matches' in df_keepers_adv.columns:\n",
        "    df_keepers_adv = df_keepers_adv.drop(columns=['Matches'])\n",
        "\n",
        "df_keepers_adv.to_csv(f\"fbref_keepersadv_{season}.csv\", index=False)\n",
        "print(f\"Saved advanced goalkeeper stats to fbref_keepersadv_{season}.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EO37QZyWLHUZ",
        "outputId": "74d51acc-d302-47aa-b3db-5df0f0c92fb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved advanced goalkeeper stats to fbref_keepersadv_2017-2018.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scraper for fbref goal and shot creation table\n",
        "url_gca = f\"https://fbref.com/en/comps/Big5/{season}/gca/players/{season}-Big-5-European-Leagues-Stats\"\n",
        "\n",
        "df_gca = pd.read_html(url_gca, attrs={\"id\": \"stats_gca\"})[0]\n",
        "df_gca.columns = [\n",
        "    '_'.join(col).strip() if isinstance(col, tuple) and 'Unnamed' not in col[0] else col[-1]\n",
        "    for col in df_gca.columns\n",
        "]\n",
        "df_gca.columns = df_gca.columns.str.strip().str.replace(r'\\s+', '_', regex=True)\n",
        "if 'Matches' in df_gca.columns:\n",
        "    df_gca = df_gca.drop(columns=['Matches'])\n",
        "\n",
        "df_gca.to_csv(f\"fbref_gca_{season}.csv\", index=False)\n",
        "print(f\"Saved goal and shot creation stats to fbref_gca_{season}.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgFhoKBCLJkN",
        "outputId": "f8cbae31-b2fe-4f90-fd22-8a1ceca0ab06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved goal and shot creation stats to fbref_gca_2017-2018.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning and merging of all the above scraped tables"
      ],
      "metadata": {
        "id": "QMYLHvxPzl6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_column_names(df):\n",
        "    df.columns = df.columns.str.strip().str.lower()\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "UzdnktOVQov8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_duplicate_columns(df):\n",
        "    return df.loc[:, ~df.columns.duplicated()]\n"
      ],
      "metadata": {
        "id": "_sT7xqioREF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_merged = pd.read_csv(f\"fbref_standard_{season}.csv\")\n",
        "final_merged = clean_column_names(final_merged)\n",
        "final_merged = remove_duplicate_columns(final_merged)\n",
        "\n",
        "print(f\"Loaded standard table with shape: {final_merged.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZqNrOWnOz0l",
        "outputId": "d1e1ed66-5555-4686-aca7-3622240e2efe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded standard table with shape: (2799, 37)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = f\"fbref_defense_{season}.csv\"\n",
        "df_defense = pd.read_csv(file)\n",
        "\n",
        "df_defense = clean_column_names(df_defense)\n",
        "df_defense = remove_duplicate_columns(df_defense)\n",
        "\n",
        "# Drop conflicting columns\n",
        "conflict_columns = {\"rk\", \"90s\", \"matches\", \"age\"}\n",
        "df_defense = df_defense.drop(columns=[col for col in conflict_columns if col in df_defense.columns], errors='ignore')\n",
        "\n",
        "# Remove row duplicates using the correct key columns\n",
        "merge_keys = [\"player\", \"born\", \"squad\"]\n",
        "df_defense = df_defense.drop_duplicates(subset=merge_keys)\n",
        "\n",
        "# Identify columns to merge without duplicates\n",
        "non_overlapping_columns = [col for col in df_defense.columns if col not in final_merged.columns]\n",
        "\n",
        "# Merge using `player`, `born`, and `squad` keys\n",
        "final_merged = pd.merge(final_merged, df_defense[merge_keys + non_overlapping_columns],\n",
        "                        on=merge_keys, how=\"left\")\n",
        "\n",
        "print(f\"Merged defense table. New shape: {final_merged.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYHrQt99O5_p",
        "outputId": "800eae59-6b31-4397-9e3d-ce0f43adce4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merged defense table. New shape: (2799, 53)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = f\"fbref_keepers_{season}.csv\"\n",
        "df_keepers = pd.read_csv(file)\n",
        "\n",
        "# Clean column names and remove duplicate columns\n",
        "df_keepers = clean_column_names(df_keepers)\n",
        "df_keepers = remove_duplicate_columns(df_keepers)\n",
        "\n",
        "# Drop conflicting columns\n",
        "df_keepers = df_keepers.drop(columns=[col for col in conflict_columns if col in df_keepers.columns], errors='ignore')\n",
        "\n",
        "# Remove row duplicates using the correct key columns\n",
        "df_keepers = df_keepers.drop_duplicates(subset=merge_keys)\n",
        "\n",
        "# Identify columns to merge without duplicates\n",
        "non_overlapping_columns = [col for col in df_keepers.columns if col not in final_merged.columns]\n",
        "\n",
        "# Merge using `player`, `born`, and `squad` keys\n",
        "final_merged = pd.merge(final_merged, df_keepers[merge_keys + non_overlapping_columns],\n",
        "                        on=merge_keys, how=\"left\")\n",
        "\n",
        "print(f\"Merged keeper table. New shape: {final_merged.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVv0_smsO6bA",
        "outputId": "59d63760-5a03-4af1-efc8-755b8181aa01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merged keeper table. New shape: (2799, 68)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = f\"fbref_passing_{season}.csv\"\n",
        "df_passing = pd.read_csv(file)\n",
        "\n",
        "# Clean column names and remove duplicate columns\n",
        "df_passing = clean_column_names(df_passing)\n",
        "df_passing = remove_duplicate_columns(df_passing)\n",
        "\n",
        "# Drop conflicting columns\n",
        "df_passing = df_passing.drop(columns=[col for col in conflict_columns if col in df_passing.columns], errors='ignore')\n",
        "\n",
        "# Remove row duplicates using the correct key columns\n",
        "df_passing = df_passing.drop_duplicates(subset=merge_keys)\n",
        "\n",
        "# Identify columns to merge without duplicates\n",
        "non_overlapping_columns = [col for col in df_passing.columns if col not in final_merged.columns]\n",
        "\n",
        "# Merge using `player`, `born`, and `squad` keys\n",
        "final_merged = pd.merge(final_merged, df_passing[merge_keys + non_overlapping_columns],\n",
        "                        on=merge_keys, how=\"left\")\n",
        "\n",
        "print(f\"Merged passing table. New shape: {final_merged.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4eTjT0fO6qH",
        "outputId": "e1cffebf-41b3-4c75-f520-9ea93886a5ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merged passing table. New shape: (2799, 91)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = f\"fbref_possession_{season}.csv\"\n",
        "df_possession = pd.read_csv(file)\n",
        "\n",
        "# Clean column names and remove duplicates\n",
        "df_possession.columns = df_possession.columns.str.strip().str.lower()\n",
        "df_possession = df_possession.loc[:, ~df_possession.columns.duplicated()]\n",
        "\n",
        "# Drop conflicting columns and duplicates\n",
        "df_possession = df_possession.drop(columns=[col for col in conflict_columns if col in df_possession.columns], errors='ignore')\n",
        "df_possession = df_possession.drop_duplicates(subset=merge_keys)\n",
        "\n",
        "# Identify columns to merge without conflicts\n",
        "non_overlapping_columns = [col for col in df_possession.columns if col not in final_merged.columns]\n",
        "\n",
        "# Merge\n",
        "final_merged = pd.merge(final_merged, df_possession[merge_keys + non_overlapping_columns], on=merge_keys, how=\"left\")\n",
        "print(f\"Merged possession table. New shape: {final_merged.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWdnds2WO64u",
        "outputId": "0aab9b0f-b97b-4470-80b1-94cd0d41d08a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merged possession table. New shape: (2799, 113)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = f\"fbref_shooting_{season}.csv\"\n",
        "df_shooting = pd.read_csv(file)\n",
        "\n",
        "# Clean column names and remove duplicates\n",
        "df_shooting.columns = df_shooting.columns.str.strip().str.lower()\n",
        "df_shooting = df_shooting.loc[:, ~df_shooting.columns.duplicated()]\n",
        "\n",
        "# Drop conflicting columns and duplicates\n",
        "df_shooting = df_shooting.drop(columns=[col for col in conflict_columns if col in df_shooting.columns], errors='ignore')\n",
        "df_shooting = df_shooting.drop_duplicates(subset=merge_keys)\n",
        "\n",
        "# Identify columns to merge without conflicts\n",
        "non_overlapping_columns = [col for col in df_shooting.columns if col not in final_merged.columns]\n",
        "\n",
        "# Merge\n",
        "final_merged = pd.merge(final_merged, df_shooting[merge_keys + non_overlapping_columns], on=merge_keys, how=\"left\")\n",
        "print(f\"Merged shooting table. New shape: {final_merged.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-VnXS4gRv0o",
        "outputId": "46d12e1d-3249-4c98-de11-d9700dde3315"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merged shooting table. New shape: (2799, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = f\"fbref_misc_{season}.csv\"\n",
        "df_misc = pd.read_csv(file)\n",
        "\n",
        "# Clean column names and remove duplicates\n",
        "df_misc.columns = df_misc.columns.str.strip().str.lower()\n",
        "df_misc = df_misc.loc[:, ~df_misc.columns.duplicated()]\n",
        "\n",
        "# Drop conflicting columns and duplicates\n",
        "df_misc = df_misc.drop(columns=[col for col in conflict_columns if col in df_misc.columns], errors='ignore')\n",
        "df_misc = df_misc.drop_duplicates(subset=merge_keys)\n",
        "\n",
        "# Identify columns to merge without conflicts\n",
        "non_overlapping_columns = [col for col in df_misc.columns if col not in final_merged.columns]\n",
        "\n",
        "# Merge\n",
        "final_merged = pd.merge(final_merged, df_misc[merge_keys + non_overlapping_columns], on=merge_keys, how=\"left\")\n",
        "print(f\"Merged misc table. New shape: {final_merged.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scmhFkIoRx2t",
        "outputId": "10395147-af85-4a4c-f6bf-103fcf17988c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merged misc table. New shape: (2799, 142)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = f\"fbref_gca_{season}.csv\"\n",
        "df_gca = pd.read_csv(file)\n",
        "\n",
        "# Clean column names and remove duplicates\n",
        "df_gca.columns = df_gca.columns.str.strip().str.lower()\n",
        "df_gca = df_gca.loc[:, ~df_gca.columns.duplicated()]\n",
        "\n",
        "# Drop conflicting columns and duplicates\n",
        "df_gca = df_gca.drop(columns=[col for col in conflict_columns if col in df_gca.columns], errors='ignore')\n",
        "df_gca = df_gca.drop_duplicates(subset=merge_keys)\n",
        "\n",
        "# Identify columns to merge without conflicts\n",
        "non_overlapping_columns = [col for col in df_gca.columns if col not in final_merged.columns]\n",
        "\n",
        "# Merge\n",
        "final_merged = pd.merge(final_merged, df_gca[merge_keys + non_overlapping_columns], on=merge_keys, how=\"left\")\n",
        "print(f\"Merged gca table. New shape: {final_merged.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzhGJn5bRzY8",
        "outputId": "023ee8a3-9f73-4f18-de82-a3d67f8513c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merged gca table. New shape: (2799, 158)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = f\"fbref_keepersadv_{season}.csv\"\n",
        "df_keepersadv = pd.read_csv(file)\n",
        "\n",
        "# Clean column names and remove duplicates\n",
        "df_keepersadv.columns = df_keepersadv.columns.str.strip().str.lower()\n",
        "df_keepersadv = df_keepersadv.loc[:, ~df_keepersadv.columns.duplicated()]\n",
        "\n",
        "# Drop conflicting columns and duplicates\n",
        "df_keepersadv = df_keepersadv.drop(columns=[col for col in conflict_columns if col in df_keepersadv.columns], errors='ignore')\n",
        "df_keepersadv = df_keepersadv.drop_duplicates(subset=merge_keys)\n",
        "\n",
        "# Identify columns to merge without conflicts\n",
        "non_overlapping_columns = [col for col in df_keepersadv.columns if col not in final_merged.columns]\n",
        "\n",
        "# Merge\n",
        "final_merged = pd.merge(final_merged, df_keepersadv[merge_keys + non_overlapping_columns], on=merge_keys, how=\"left\")\n",
        "print(f\"Merged advanced keeper table. New shape: {final_merged.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLg6mBDzSS4-",
        "outputId": "aeaebc0d-1835-4177-8faf-ab1c0cf93baa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merged advanced keeper table. New shape: (2799, 183)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add season column\n",
        "final_merged['season'] = season\n",
        "\n",
        "# Save the final merged data\n",
        "final_merged.to_csv(f\"fbref_merged_{season}.csv\", index=False)\n",
        "print(f\"Saved merged season data to fbref_merged_{season}.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WuHJ2PfR0wL",
        "outputId": "85994e4f-566c-458f-c351-507dcc0a80b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved merged season data to fbref_merged_2017-2018.csv\n"
          ]
        }
      ]
    }
  ]
}